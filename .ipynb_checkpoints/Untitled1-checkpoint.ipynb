{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ee0cf764-981c-4723-9cd3-b72c5d51aeb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Ardha Baddha Padmottanasana: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 108/108 [00:11<00:00,  9.06it/s]\n",
      "Processing Baddha Padmasana: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 65/65 [00:07<00:00,  8.49it/s]\n",
      "Processing Eka Pada Rajakapotasana: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 53/53 [00:06<00:00,  8.43it/s]\n",
      "Processing Hanumanasana: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 41/41 [00:05<00:00,  7.69it/s]\n",
      "Processing Padma Mayurasana: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 65/65 [00:07<00:00,  9.05it/s]\n",
      "Processing Padma Sarvangasana: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 55/55 [00:05<00:00,  9.80it/s]\n",
      "Processing Upavistha Konasana: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 17/17 [00:01<00:00,  9.03it/s]\n",
      "Processing Urdhva Dandasana: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 50/50 [00:05<00:00,  9.36it/s]\n",
      "Processing Urdhva Dhanurasana: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 74/74 [00:07<00:00,  9.53it/s]\n",
      "Processing Ardh Uttanasana: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 71/71 [00:08<00:00,  8.85it/s]\n",
      "Processing Baddha Konasana: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 81/81 [00:09<00:00,  8.37it/s]\n",
      "Processing Malasana: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 73/73 [00:08<00:00,  8.93it/s]\n",
      "Processing Tadasana: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 84/84 [00:09<00:00,  8.54it/s]\n",
      "Processing urdhva hastasana: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 47/47 [00:05<00:00,  8.94it/s]\n",
      "Processing Utkatasana: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 81/81 [00:08<00:00,  9.22it/s]\n",
      "Processing Utthita Trikonasana: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:10<00:00,  9.06it/s]\n",
      "Processing vajrasana: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 84/84 [00:10<00:00,  7.99it/s]\n",
      "Processing Vrksasana: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 68/68 [00:08<00:00,  7.93it/s]\n",
      "Processing Ardha Kapotasana: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 60/60 [00:06<00:00,  9.14it/s]\n",
      "Processing Ashtanga Namaskara: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 85/85 [00:08<00:00,  9.68it/s]\n",
      "Processing bhujangasana: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 73/73 [00:08<00:00,  8.65it/s]\n",
      "Processing chaturanga dandasana: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 90/90 [00:10<00:00,  8.77it/s]\n",
      "Processing Dhanurasana: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 54/54 [00:05<00:00,  9.16it/s]\n",
      "Processing krounchasana: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 45/45 [00:05<00:00,  8.71it/s]\n",
      "Processing Padmasana: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 77/77 [00:09<00:00,  8.34it/s]\n",
      "Processing salamba sirsasana: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 60/60 [00:06<00:00,  9.24it/s]\n",
      "Processing Ustrasana: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:11<00:00,  8.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Keypoints extraction complete! Saved as 'yoga_keypoints.csv'\n"
     ]
    }
   ],
   "source": [
    "# Data Collection\n",
    "\n",
    "import os\n",
    "import cv2\n",
    "import mediapipe as mp\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "mp_pose = mp.solutions.pose\n",
    "pose = mp_pose.Pose(static_image_mode=True)\n",
    "\n",
    "# Initialize the dataset list\n",
    "dataset = []\n",
    "\n",
    "# Define your folder path\n",
    "base_path = \"dataset\"\n",
    "\n",
    "# Go through levels â†’ asanas â†’ images\n",
    "for level in os.listdir(base_path):\n",
    "    level_path = os.path.join(base_path, level)\n",
    "    if not os.path.isdir(level_path):\n",
    "        continue\n",
    "\n",
    "    for asana in os.listdir(level_path):\n",
    "        asana_path = os.path.join(level_path, asana)\n",
    "        if not os.path.isdir(asana_path):\n",
    "            continue\n",
    "\n",
    "        for img_name in tqdm(os.listdir(asana_path), desc=f\"Processing {asana}\"):\n",
    "            img_path = os.path.join(asana_path, img_name)\n",
    "\n",
    "            try:\n",
    "                image = cv2.imread(img_path)\n",
    "                image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "                result = pose.process(image_rgb)\n",
    "\n",
    "                if result.pose_landmarks:\n",
    "                    keypoints = []\n",
    "                    for lm in result.pose_landmarks.landmark:\n",
    "                        keypoints.extend([lm.x, lm.y, lm.visibility])\n",
    "                    \n",
    "                    keypoints.append(asana)  # Add label at end\n",
    "                    dataset.append(keypoints)\n",
    "            except:\n",
    "                print(f\"Skipped: {img_path}\")\n",
    "                continue\n",
    "\n",
    "pose.close()\n",
    "\n",
    "# Create column names\n",
    "columns = []\n",
    "for i in range(33):  # 33 landmarks in MediaPipe pose\n",
    "    columns += [f\"x{i}\", f\"y{i}\", f\"v{i}\"]\n",
    "columns.append(\"label\")\n",
    "\n",
    "# Save to CSV\n",
    "df = pd.DataFrame(dataset, columns=columns)\n",
    "df.to_csv(\"yoga_keypoints.csv\", index=False)\n",
    "\n",
    "print(\"âœ… Keypoints extraction complete! Saved as 'yoga_keypoints.csv'\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c83089cf-2a92-4a8b-937b-61a556863a71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of dataset: (1683, 100)\n",
      "Labels: ['Ardha Baddha Padmottanasana' 'Baddha Padmasana'\n",
      " 'Eka Pada Rajakapotasana' 'Hanumanasana' 'Padma Mayurasana'\n",
      " 'Padma Sarvangasana' 'Upavistha Konasana' 'Urdhva Dandasana'\n",
      " 'Urdhva Dhanurasana' 'Ardh Uttanasana' 'Baddha Konasana' 'Malasana'\n",
      " 'Tadasana' 'urdhva hastasana' 'Utkatasana' 'Utthita Trikonasana'\n",
      " 'vajrasana' 'Vrksasana' 'Ardha Kapotasana' 'Ashtanga Namaskara'\n",
      " 'bhujangasana' 'chaturanga dandasana' 'Dhanurasana' 'krounchasana'\n",
      " 'Padmasana' 'salamba sirsasana' 'Ustrasana']\n",
      "Label Encoding: {'Ardh Uttanasana': 0, 'Ardha Baddha Padmottanasana': 1, 'Ardha Kapotasana': 2, 'Ashtanga Namaskara': 3, 'Baddha Konasana': 4, 'Baddha Padmasana': 5, 'Dhanurasana': 6, 'Eka Pada Rajakapotasana': 7, 'Hanumanasana': 8, 'Malasana': 9, 'Padma Mayurasana': 10, 'Padma Sarvangasana': 11, 'Padmasana': 12, 'Tadasana': 13, 'Upavistha Konasana': 14, 'Urdhva Dandasana': 15, 'Urdhva Dhanurasana': 16, 'Ustrasana': 17, 'Utkatasana': 18, 'Utthita Trikonasana': 19, 'Vrksasana': 20, 'bhujangasana': 21, 'chaturanga dandasana': 22, 'krounchasana': 23, 'salamba sirsasana': 24, 'urdhva hastasana': 25, 'vajrasana': 26}\n",
      "âœ… Preprocessing complete! Ready to train ML model.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "\n",
    "# Step 1: Load the keypoints dataset\n",
    "df = pd.read_csv(\"yoga_keypoints.csv\")\n",
    "print(\"Shape of dataset:\", df.shape)\n",
    "print(\"Labels:\", df['label'].unique())\n",
    "\n",
    "# Step 2: Split into features (X) and labels (y)\n",
    "X = df.drop(\"label\", axis=1)\n",
    "y = df[\"label\"]\n",
    "\n",
    "# Step 3: Encode the labels\n",
    "le = LabelEncoder()\n",
    "y_encoded = le.fit_transform(y)\n",
    "\n",
    "# Save label mapping for future reference (like live prediction)\n",
    "label_map = dict(zip(le.classes_, le.transform(le.classes_)))\n",
    "print(\"Label Encoding:\", label_map)\n",
    "\n",
    "# Step 4: Normalize the features\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Step 5: Split into train/test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y_encoded, test_size=0.2, random_state=42)\n",
    "\n",
    "print(\"âœ… Preprocessing complete! Ready to train ML model.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fbef9adc-eb96-468d-8a1e-b1b98f9a7d04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸŽ¯ Accuracy on Test Set: 80.12 %\n",
      "\n",
      "ðŸ“Š Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.71      0.69        14\n",
      "           1       0.71      0.67      0.69        18\n",
      "           2       0.73      0.73      0.73        11\n",
      "           3       0.71      0.88      0.79        17\n",
      "           4       0.94      0.76      0.84        21\n",
      "           5       0.78      0.64      0.70        11\n",
      "           6       0.88      1.00      0.93         7\n",
      "           7       1.00      0.67      0.80         9\n",
      "           8       0.83      0.62      0.71         8\n",
      "           9       0.91      0.71      0.80        14\n",
      "          10       0.68      0.93      0.79        14\n",
      "          11       0.60      0.75      0.67         8\n",
      "          12       0.69      1.00      0.82         9\n",
      "          13       0.75      0.71      0.73        17\n",
      "          14       1.00      0.40      0.57         5\n",
      "          15       0.80      0.89      0.84         9\n",
      "          16       1.00      0.80      0.89        15\n",
      "          17       0.76      0.87      0.81        15\n",
      "          18       0.85      0.85      0.85        13\n",
      "          19       0.79      0.94      0.86        16\n",
      "          20       0.82      0.93      0.88        15\n",
      "          21       0.62      0.71      0.67         7\n",
      "          22       1.00      0.83      0.91        24\n",
      "          23       0.86      1.00      0.92         6\n",
      "          24       0.88      1.00      0.93         7\n",
      "          25       0.80      0.50      0.62         8\n",
      "          26       0.85      0.89      0.87        19\n",
      "\n",
      "    accuracy                           0.80       337\n",
      "   macro avg       0.81      0.79      0.79       337\n",
      "weighted avg       0.82      0.80      0.80       337\n",
      "\n",
      "\n",
      "ðŸ” Confusion Matrix:\n",
      " [[10  2  0  0  0  0  0  0  0  0  2  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "   0  0  0]\n",
      " [ 4 12  0  0  0  0  0  0  0  1  1  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "   0  0  0]\n",
      " [ 0  0  8  0  0  0  0  0  0  0  0  1  1  0  0  0  0  1  0  0  0  0  0  0\n",
      "   0  0  0]\n",
      " [ 0  1  0 15  0  0  0  0  0  0  1  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "   0  0  0]\n",
      " [ 0  0  0  0 16  1  0  0  0  0  0  1  3  0  0  0  0  0  0  0  0  0  0  0\n",
      "   0  0  0]\n",
      " [ 0  0  0  0  0  7  0  0  0  0  0  1  0  1  0  0  0  0  0  0  0  1  0  0\n",
      "   0  0  1]\n",
      " [ 0  0  0  0  0  0  7  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "   0  0  0]\n",
      " [ 0  0  0  0  0  0  0  6  0  0  0  0  0  0  0  0  0  0  0  1  1  1  0  0\n",
      "   0  0  0]\n",
      " [ 0  0  0  0  0  1  0  0  5  0  0  0  0  0  0  0  0  1  0  0  0  1  0  0\n",
      "   0  0  0]\n",
      " [ 1  2  0  0  0  0  0  0  0 10  1  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "   0  0  0]\n",
      " [ 0  0  0  1  0  0  0  0  0  0 13  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "   0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  6  0  0  0  1  0  0  0  1  0  0  0  0\n",
      "   0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  9  0  0  0  0  0  0  0  0  0  0  0\n",
      "   0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  1  0  0  0  0 12  0  0  0  1  2  0  0  0  0  0\n",
      "   0  1  0]\n",
      " [ 0  0  2  1  0  0  0  0  0  0  0  0  0  0  2  0  0  0  0  0  0  0  0  0\n",
      "   0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  1  0  0  0  0  8  0  0  0  0  0  0  0  0\n",
      "   0  0  0]\n",
      " [ 0  0  0  0  0  0  1  0  0  0  0  0  0  0  0  1 12  0  0  0  0  0  0  0\n",
      "   1  0  0]\n",
      " [ 0  0  0  1  0  0  0  0  0  0  0  0  0  0  0  0  0 13  0  0  0  0  0  0\n",
      "   0  0  1]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 11  2  0  0  0  0\n",
      "   0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  1  0 15  0  0  0  0\n",
      "   0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  1  0  0  0  0  0  0 14  0  0  0\n",
      "   0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  1  5  0  0\n",
      "   0  0  1]\n",
      " [ 0  0  0  3  1  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 20  0\n",
      "   0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  6\n",
      "   0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "   7  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  2  0  0  0  0  0  0  1  0  0  1\n",
      "   0  4  0]\n",
      " [ 0  0  1  0  0  0  0  0  0  0  0  1  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "   0  0 17]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['label_encoder.pkl']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "import joblib\n",
    "\n",
    "# Step 1: Create the model\n",
    "model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "\n",
    "# Step 2: Train it\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Step 3: Evaluate\n",
    "y_pred = model.predict(X_test)\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "\n",
    "print(\"ðŸŽ¯ Accuracy on Test Set:\", round(acc * 100, 2), \"%\")\n",
    "print(\"\\nðŸ“Š Classification Report:\\n\", classification_report(y_test, y_pred))\n",
    "print(\"\\nðŸ” Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n",
    "\n",
    "# Step 4: Save the model for later webcam prediction\n",
    "joblib.dump(model, \"yoga_pose_model.pkl\")\n",
    "joblib.dump(scaler, \"scaler.pkl\")\n",
    "joblib.dump(le, \"label_encoder.pkl\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb34f3f3-2233-4700-9ac4-f0222b843f7d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
